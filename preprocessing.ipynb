{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMost of the code is from:\\nhttps://www.kaggle.com/code/jirkaborovec/bloodclots-eda-load-wsi-prune-background/notebook\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "'''\n",
    "Most of the code is from:\n",
    "https://www.kaggle.com/code/jirkaborovec/bloodclots-eda-load-wsi-prune-background/notebook\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = './data/'\n",
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_csv = os.path.join(DATASET_FOLDER, \"train.csv\")\n",
    "df_train = pd.read_csv(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_median(im, val=255):\n",
    "    '''\n",
    "    Creates the mask where the value is greater or lower than the median for each color map, to decide whether\n",
    "    to delete row/column or not (in prune_image_rows_cols function). \n",
    "    To work properly assumes the background is white (0,0,0).\n",
    "    '''\n",
    "    masks = [None] * 3\n",
    "    \n",
    "    for c in range(3):\n",
    "        masks[c] = im[..., c] >= np.median(im[:, :, c]) - 5\n",
    "        \n",
    "    mask = np.logical_and(*masks)\n",
    "    im[mask, :] = val\n",
    "    \n",
    "    return im, mask\n",
    "\n",
    "\n",
    "def prune_image_rows_cols(im, mask, thr=0.990):\n",
    "    '''\n",
    "    Deletes rows and columns where the number of pixels in the mask is greater than the threshold\n",
    "    '''\n",
    "    \n",
    "    # delete empty columns\n",
    "    for l in reversed(range(im.shape[1])):\n",
    "        if (np.sum(mask[:, l]) / float(mask.shape[0])) > thr:\n",
    "            im = np.delete(im, l, 1)\n",
    "            \n",
    "    # delete empty rows\n",
    "    for l in reversed(range(im.shape[0])):\n",
    "        if (np.sum(mask[l, :]) / float(mask.shape[1])) > thr:\n",
    "            im = np.delete(im, l, 0)\n",
    "            \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_load_scale_norm(img_path, prune_thr=0.990, bg_val=255):\n",
    "    '''\n",
    "    Prunes the image, and resizes the image if they still to big\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    scale = min(img.height / 2e3, img.width / 2e3)\n",
    "    \n",
    "    if scale > 1:\n",
    "        tmp_size = int(img.width / scale), int(img.height / scale)\n",
    "        img.thumbnail(tmp_size, resample=Image.Resampling.BILINEAR, reducing_gap=scale)\n",
    "        \n",
    "    im, mask = mask_median(np.array(img), val=bg_val)\n",
    "    im = prune_image_rows_cols(im, mask, thr=prune_thr)\n",
    "    img = Image.fromarray(im)\n",
    "    scale = min(img.height / 1e3, img.width / 1e3)\n",
    "    \n",
    "    if scale > 1:\n",
    "        img = img.resize((int(img.width / scale), int(img.height / scale)), Image.Resampling.LANCZOS)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_id):\n",
    "    '''\n",
    "    Gets and image and creates the preprocessed one in the \"train_images\" folder.\n",
    "    '''\n",
    "    img_path = os.path.join(DATASET_FOLDER, \"train\", f\"{image_id}.tif\")\n",
    "    img = image_load_scale_norm(img_path)\n",
    "    \n",
    "    if not img:\n",
    "        return\n",
    "    \n",
    "    img.save(os.path.join(DATASET_FOLDER, \"train_images\", f\"{image_id}.png\"))\n",
    "    del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if N_JOBS == 1:\n",
    "    for name in tqdm(df_train[\"image_id\"]):\n",
    "        preprocess_image(name)\n",
    "else: \n",
    "    # It has problems with space\n",
    "    with multiprocessing.Pool(processes=os.cpu_count() if N_JOBS == -1 else N_JOBS) as pool:\n",
    "        pool.map(\n",
    "            func=preprocess_image, \n",
    "            iterable=[name for name in df_train[\"image_id\"]]\n",
    "        )\n",
    "\n",
    "        pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.morphology import binary_closing, binary_dilation, disk\n",
    "\n",
    "\n",
    "def optical_density(tile):\n",
    "    \"\"\"\n",
    "    Convert a tile to optical density values.\n",
    "    \n",
    "    Code from (deep-histopath/deephistopath/preprocessing.py): \n",
    "    https://github.com/CODAIT/deep-histopath/tree/c8baf8d47b6c08c0f6c7b1fb6d5dd6b77e711c33\n",
    "\n",
    "    Args:\n",
    "    tile (np.array): A 3D NumPy array of shape (tile_size, tile_size, channels).\n",
    "\n",
    "    Returns:\n",
    "    A 3D NumPy array of shape (tile_size, tile_size, channels) representing optical density values.\n",
    "    \"\"\"\n",
    "    tile = tile.astype(np.float64)\n",
    "    #od = -np.log10(tile/255 + 1e-8)\n",
    "    od = -np.log((tile+1)/240)\n",
    "    return od\n",
    "\n",
    "\n",
    "def keep_tile(tile:np.array, tile_size:int, tissue_threshold:float=0.9)->bool:\n",
    "    \"\"\"\n",
    "    Determine if a tile should be kept.\n",
    "    \n",
    "    This filters out tiles based on size and a tissue percentage\n",
    "    threshold, using a custom algorithm. If a tile has height &\n",
    "    width equal to (tile_size, tile_size), and contains greater\n",
    "    than or equal to the given percentage, then it will be kept;\n",
    "    otherwise it will be filtered out.\n",
    "    \n",
    "    Check 1:\n",
    "    Uses edge detection (Canny) to see where the tissue is, as the\n",
    "    tissue should be full of edges while the background should not.\n",
    "    The algorithm follows the following steps: \n",
    "        . Convert image from RGB to gray\n",
    "        . Canny (for edge detection)\n",
    "        . Closing (dilatation -> erosion)\n",
    "        . Dilatation\n",
    "        . Fill holes\n",
    "        . Percentage of binary image that represent the % of tissue (check with tissue_threshold)\n",
    "        \n",
    "    Check 2:\n",
    "    It is based on the optical density of the image.\n",
    "    The algorithm follows the following steps: \n",
    "        . Calculate the optical density values of the tile\n",
    "        . Binarize the image with the threshold of 0.15\n",
    "        . Closing (dilatation -> erosion)\n",
    "        . Dilatation\n",
    "        . Fill holes\n",
    "        . Percentage of binary image that represent the % of tissue (check with tissue_threshold)\n",
    "        \n",
    "    Code from (deep-histopath/deephistopath/preprocessing.py): \n",
    "    https://github.com/CODAIT/deep-histopath/tree/c8baf8d47b6c08c0f6c7b1fb6d5dd6b77e711c33\n",
    "\n",
    "    Args:\n",
    "        tile (np.array): 3D NumPy array with the tile of shape (width, height, 3).\n",
    "        tile_size (int): Desired tile size.\n",
    "        tissue_threshold (float, optional): Percentage of the image that has to be tissue. Defaults to 0.9.\n",
    "\n",
    "    Returns:\n",
    "        bool: A Boolean indicating whether or not a tile should be kept for future usage.\n",
    "    \"\"\"\n",
    "    if tile.shape[0:2] != (tile_size, tile_size):\n",
    "        return False\n",
    "    \n",
    "    tile_orig = tile.copy()\n",
    "    \n",
    "    # Check 1\n",
    "    tile = rgb2gray(tile)\n",
    "    tile = 1 - tile # Binary image where 0 = background, 1 = dense tissue\n",
    "    tile = canny(tile)\n",
    "    tile = binary_closing(tile, disk(10))\n",
    "    tile = binary_dilation(tile, disk(10))\n",
    "    tile = binary_fill_holes(tile)\n",
    "    percentage = tile.mean()\n",
    "    check1 = percentage >= tissue_threshold\n",
    "    \n",
    "    # Check 2\n",
    "    tile = optical_density(tile_orig)\n",
    "    beta = 0.15\n",
    "    tile = np.min(tile, axis=2) >= beta\n",
    "    tile = binary_closing(tile, disk(2))\n",
    "    tile = binary_dilation(tile, disk(2))\n",
    "    tile = binary_fill_holes(tile)\n",
    "    percentage = tile.mean()\n",
    "    check2 = percentage >= tissue_threshold\n",
    "    \n",
    "    return check1 and check2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSI:\n",
    "    def __init__(self, path:str, tile_size:int=256, overlap:int=0, tile_level:int=-1, tissue_threshold:float=0.90):\n",
    "        self.path = path\n",
    "        self.tile_size = tile_size\n",
    "        self.overlap = overlap\n",
    "        self.tile_level = tile_level\n",
    "        self.tissue_threshold = tissue_threshold\n",
    "        \n",
    "        self.slide = open_slide(self.path)\n",
    "        self.generator = DeepZoomGenerator(self.slide, tile_size=self.tile_size, overlap=self.overlap)\n",
    "        self.tiles = create_tiles\n",
    "    \n",
    "    def get_top_N_tiles(self, N:int, target_dir:str=self.path)->Tuple[Tile, ...]:\n",
    "        pass\n",
    "    \n",
    "    def _create_tiles(\n",
    "    generator:DeepZoomGenerator,\n",
    "    tile_level:int,\n",
    "    tile_size:int,\n",
    "    tissue_threshold:float\n",
    ")->Tuple[Tile, ...]:\n",
    "    \n",
    "    cols, rows = generator.level_tiles[tile_level]\n",
    "\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            tile = generator.get_tile(tile_level, (col, row))\n",
    "            tile_np = np.array(tile)\n",
    "            \n",
    "            if _keep_tile(tile_np, tile_size, tissue_threshold):\n",
    "                tile.save(os.path.join(target_dir, f\"{base_image_name}-{count}.png\"))\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tile:\n",
    "    def __init__(self, tile:Image, col:int, row:int, basename:str):\n",
    "        self.tile = tile\n",
    "        self.col = col\n",
    "        self.row = row\n",
    "        self.basename = basename\n",
    "        self.tissue_percentage = _tissue_percentage\n",
    "        \n",
    "    def _tissue_percentage(self, tile):\n",
    "        \n",
    "    \n",
    "    def save_tile(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lista -> [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n",
      "indice -> 15\n",
      "post precessing -> 15\n",
      "valor obtido -> 15\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "691edecb9f7cb7a0b3f20db7bfc8f0324b9aa74136e160810d1d33591264aaa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
