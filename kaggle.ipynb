{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from typing import Tuple, Union, List, Dict\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = './models/final_models/convnext_base-batch_size=128-epochs=20-lr=0.003-1660509636.671306.pt'\n",
    "\n",
    "TRAIN_TEST_SET = 'train'\n",
    "TABULAR_DATA_PATH = f'./data/{TRAIN_TEST_SET}.csv'\n",
    "test_df = pd.read_csv(TABULAR_DATA_PATH)\n",
    "IMAGE_PATH = f'./data/images/'\n",
    "\n",
    "PREPROCESS_IMAGES = False\n",
    "MAX_IMAGE_SIZE = 1_000_000_000 # If image is larger than 1.0GB then a black square will be used\n",
    "N_JOBS = 1\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_median(im, val=255):\n",
    "    '''\n",
    "    Creates the mask where the value is greater or lower than the median for each color map, to decide whether\n",
    "    to delete row/column or not (in prune_image_rows_cols function). \n",
    "    To work properly assumes the background is white (0,0,0).\n",
    "    '''\n",
    "    masks = [None] * 3\n",
    "    \n",
    "    for c in range(3):\n",
    "        masks[c] = im[..., c] >= np.median(im[:, :, c]) - 5\n",
    "        \n",
    "    mask = np.logical_and(*masks)\n",
    "    im[mask, :] = val\n",
    "    \n",
    "    return im, mask\n",
    "\n",
    "\n",
    "def prune_image_rows_cols(im, mask, thr=0.990):\n",
    "    '''\n",
    "    Deletes rows and columns where the number of pixels in the mask is greater than the threshold\n",
    "    '''\n",
    "    \n",
    "    # delete empty columns\n",
    "    for l in reversed(range(im.shape[1])):\n",
    "        if (np.sum(mask[:, l]) / float(mask.shape[0])) > thr:\n",
    "            im = np.delete(im, l, 1)\n",
    "            \n",
    "    # delete empty rows\n",
    "    for l in reversed(range(im.shape[0])):\n",
    "        if (np.sum(mask[l, :]) / float(mask.shape[1])) > thr:\n",
    "            im = np.delete(im, l, 0)\n",
    "            \n",
    "    return im\n",
    "\n",
    "\n",
    "def image_load_scale_norm(img_path, prune_thr=0.990, bg_val=255):\n",
    "    '''\n",
    "    Prunes the image, and resizes the image if they still to big\n",
    "    '''\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    scale = min(img.height / 2e3, img.width / 2e3)\n",
    "    \n",
    "    if scale > 1:\n",
    "        tmp_size = int(img.width / scale), int(img.height / scale)\n",
    "        img.thumbnail(tmp_size, resample=Image.Resampling.BILINEAR, reducing_gap=scale)\n",
    "        \n",
    "    im, mask = mask_median(np.array(img), val=bg_val)\n",
    "    im = prune_image_rows_cols(im, mask, thr=prune_thr)\n",
    "    img = Image.fromarray(im)\n",
    "    scale = min(img.height / 1e3, img.width / 1e3)\n",
    "    \n",
    "    if scale > 1:\n",
    "        img = img.resize((int(img.width / scale), int(img.height / scale)), Image.Resampling.LANCZOS)\n",
    "        \n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_image(input_dir, target_dir, image_id, max_image_size=1_000_000_000):\n",
    "    '''\n",
    "    Gets and image and creates the preprocessed one in the \"train_images\" folder.\n",
    "    '''\n",
    "    img_path = os.path.join(input_dir, f\"{image_id}.tif\")\n",
    "    \n",
    "    if os.path.getsize(img_path) > max_image_size:\n",
    "        img = Image.fromarray(np.zeros((512,512,3), np.uint8))\n",
    "    else:\n",
    "        img = image_load_scale_norm(img_path)\n",
    "    \n",
    "    img.save(os.path.join(target_dir, f\"{image_id}.png\"))\n",
    "    \n",
    "    del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MayoClinicDataset(Dataset):\n",
    "    def __init__(self, csv_file:Union[str, pd.DataFrame], root_dir:str, transform:transforms.Compose=None) -> None:\n",
    "        super().__init__()\n",
    "        self.tabular_data = pd.read_csv(csv_file) if isinstance(csv_file, str) else csv_file\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.train = 'label' in self.tabular_data.columns\n",
    "        self.classes, self.class_to_idx = self._find_classes(self.tabular_data) if self.train else (['CE', 'LAA'], {'CE':0, 'LAA':1})\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.tabular_data)\n",
    "    \n",
    "    def __getitem__(self, index:int) -> Tuple[torch.Tensor, int]:\n",
    "        img_path = os.path.join(self.root_dir, self.tabular_data['image_id'].iloc[index])\n",
    "        image = Image.open(f'{img_path}.png')\n",
    "        \n",
    "        label = self.class_to_idx[self.tabular_data['label'].iloc[index]] if self.train else -1\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return (image, label)\n",
    "    \n",
    "    def _find_classes(self, tabular_data:pd.DataFrame) -> Tuple[List[str], Dict[str, int]]:\n",
    "        classes = list(sorted(tabular_data['label'].unique()))\n",
    "        class_to_idx = {classes[i]:i for i in range(len(classes))}\n",
    "        \n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TTA_dataloader(\n",
    "    tabular_data:Union[str, pd.DataFrame],\n",
    "    img_root_dir:str,\n",
    "    base_transforms:transforms.Compose,\n",
    "    aug_transforms:transforms.Compose,\n",
    "    batch_size:int=1,\n",
    "    num_workers:int=0\n",
    ") -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, List[str]]:\n",
    "    \"\"\"\n",
    "    Creates Dataloaders for the tabular dataframe given to be used with TTA predictions, based on MayoClinicDataset. \n",
    "\n",
    "    Args:\n",
    "        tabular_data (Union[str, pd.DataFrame]): Path or pandas Dataframe to tabular data.\n",
    "        img_root_dir (str): Path to the image folder.\n",
    "        base_transforms (transforms.Compose): Compose to indicate which tranformation, without any data augmentation. \n",
    "        Ex: Resize, ToTensor,...\n",
    "        aug_transforms (transforms.Compose): Compose to indicate which tranformation, with data augmentation steps.\n",
    "        batch_size (int, optional): Number of samples per batch in each of the DataLoaders. Defaults to 1.\n",
    "        num_workers (int, optional): Number of workers (cpu's). Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader, List[str]]: Returns a Tuple with the \n",
    "        base Dataloader, the augment Dataloader and the target classes labels\n",
    "    \"\"\"\n",
    "\n",
    "    base_dataset = MayoClinicDataset(tabular_data, img_root_dir, base_transforms)\n",
    "    \n",
    "    classes = base_dataset.classes\n",
    "    \n",
    "    base_dataloader = DataLoader(\n",
    "        dataset=base_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    \n",
    "    augment_dataloader = DataLoader(\n",
    "        dataset=MayoClinicDataset(tabular_data, img_root_dir, aug_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "    )                                        \n",
    "            \n",
    "    return base_dataloader, augment_dataloader, classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_b0_model():\n",
    "    weights = models.EfficientNet_B0_Weights.DEFAULT\n",
    "    model = models.efficientnet_b0(weights=weights)\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.50),\n",
    "        nn.Linear(in_features=1280, out_features=1, bias=True)\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_efficientnet_b4_model():\n",
    "    weights = models.EfficientNet_B4_Weights.DEFAULT\n",
    "    model = models.efficientnet_b4(weights=weights)\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.50),\n",
    "        nn.Linear(in_features=1792, out_features=1, bias=True),\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_efficientnet_v2_model(size):\n",
    "    if size == 's' or size == 'small':\n",
    "        weights = models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "        model = models.efficientnet_v2_s(weights=weights)\n",
    "        \n",
    "    if size == 'm' or size == 'medium':\n",
    "        weights = models.EfficientNet_V2_M_Weights.DEFAULT\n",
    "        model = models.efficientnet_v2_m(weights=weights)\n",
    "        \n",
    "    if size == 'l' or size == 'large':\n",
    "        weights = models.EfficientNet_V2_L_Weights.DEFAULT\n",
    "        model = models.efficientnet_v2_l(weights=weights)\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.50),\n",
    "        nn.Linear(in_features=1280, out_features=1, bias=True),\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_convnext_model(size):\n",
    "    if size == 't' or size == 'tiny':\n",
    "        weights = models.ConvNeXt_Tiny_Weights.DEFAULT\n",
    "        model = models.convnext_tiny(weights=weights)\n",
    "        in_features = 768\n",
    "        \n",
    "    if size == 's' or size == 'small':\n",
    "        weights = models.ConvNeXt_Small_Weights.DEFAULT\n",
    "        model = models.convnext_small(weights=weights)\n",
    "        in_features = 768\n",
    "        \n",
    "    if size == 'b' or size == 'base':\n",
    "        weights = models.ConvNeXt_Base_Weights.DEFAULT\n",
    "        model = models.convnext_base(weights=weights)\n",
    "        in_features = 1024\n",
    "        \n",
    "    if size == 'l' or size == 'large':\n",
    "        weights = models.ConvNeXt_Large_Weights.DEFAULT\n",
    "        model = models.convnext_large(weights=weights)\n",
    "        in_features = 1536\n",
    "    \n",
    "    for param in model.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    class LayerNorm2d(nn.LayerNorm):\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            x = x.permute(0, 2, 3, 1)\n",
    "            x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "            return x\n",
    "    \n",
    "    model.classifier = nn.Sequential(\n",
    "        LayerNorm2d((in_features,), eps=1e-06, elementwise_affine=True),\n",
    "        nn.Flatten(start_dim=1, end_dim=-1),\n",
    "        nn.Linear(in_features=in_features, out_features=1, bias=True)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model: torch.nn.Module,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Makes predictions for all the samples in the DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader with data to predict (data should not be shuffled).\n",
    "        device (torch.device): Device.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Predictions of the probabilities and observerd classes.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    ys = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            test_pred_logits = model(X).flatten().type(torch.float64)\n",
    "\n",
    "            ys.append(y)\n",
    "            predictions.append(torch.sigmoid(test_pred_logits))\n",
    "\n",
    "    return torch.cat(predictions), torch.cat(ys)\n",
    "\n",
    "\n",
    "def predict_TTA(\n",
    "    model:torch.nn.Module,\n",
    "    base_dataloader:torch.utils.data.DataLoader,\n",
    "    aug_dataloader:torch.utils.data.DataLoader,\n",
    "    device:torch.device,\n",
    "    n_aug_samples:int=4,\n",
    "    beta:float=0.25,\n",
    "    use_max:bool=False\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Uses Test Time Augmentation to make predictions.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model.\n",
    "        base_dataloader (torch.utils.data.DataLoader): DataLoader with data to predict, without the data augmentation \n",
    "        steps (data should not be shuffled). \n",
    "        aug_dataloader (torch.utils.data.DataLoader): DataLoader with data to predict, with the data augmentation \n",
    "        steps (data should not be shuffled). \n",
    "        device (torch.device): Device.\n",
    "        n_aug_samples (int, optional): Number of times to transform the data and make predictions on it. Defaults to 4.\n",
    "        beta (float, optional): Importance given to prediction of augmented predictions. Defaults to 0.25.\n",
    "        use_max (bool, optional): Whether or not to use maximum values for predictions. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Predictions of the probabilities and observed classes.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    aug_predictions = []\n",
    "\n",
    "    with tqdm(total=n_aug_samples+1) as pbar:\n",
    "        predictions, targets = predict(model, base_dataloader, device)\n",
    "        \n",
    "        pbar.update()\n",
    "        \n",
    "        for _ in range(n_aug_samples):\n",
    "            aug_predictions.append(predict(model, aug_dataloader, device)[0])\n",
    "            pbar.update()\n",
    "            \n",
    "    aug_predictions = torch.stack(aug_predictions)\n",
    "    aug_predictions = aug_predictions.max(0)[0] if use_max else aug_predictions.mean(0)\n",
    "                \n",
    "    if use_max: return targets, torch.stack([predictions, aug_predictions], 0).max(0)[0]\n",
    "    predictions = torch.lerp(aug_predictions, predictions, beta)\n",
    "\n",
    "    return predictions, targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_logarithmic_loss(y_true:List[int], y_preds:Tuple[List])->float:\n",
    "    \"\"\"\n",
    "    Calculates the weighted multi-class logarithmic loss. \n",
    "    The code is not optimized as it assumes the weights for each class to be the same (1/nr_classes),\n",
    "    however it does not take this assumpytion into consideration when calculating the loss.\n",
    "\n",
    "    Args:\n",
    "        y_true (List[int]): True values.\n",
    "        y_preds (Tuple[List]): Predicted values\n",
    "\n",
    "    Returns:\n",
    "        float: Mean loss value.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    \n",
    "    if not isinstance(y_true, (np.ndarray, np.generic)):\n",
    "        y_true = np.array(y_true)\n",
    "        \n",
    "    if not isinstance(y_preds, (np.ndarray, np.generic)):\n",
    "        y_preds = np.array(y_preds)\n",
    "        \n",
    "    classes, counts = np.unique(y_true, return_counts=True)\n",
    "    nr_classes = len(classes)\n",
    "    \n",
    "    # Gives same weight to every class 1/number of class\n",
    "    w = np.zeros(nr_classes) + 1/nr_classes\n",
    "        \n",
    "    # Normalize predictions\n",
    "    y_preds = y_preds/np.expand_dims(np.sum(y_preds, axis=1), axis=-1)\n",
    "    \n",
    "    # Clip predicted probabilities\n",
    "    y_preds = np.clip(y_preds, 10**-15, 1-10**-15)\n",
    "    \n",
    "    for true, preds in zip(y_true, y_preds):\n",
    "        for i in range(nr_classes):\n",
    "            if true != classes[i]:\n",
    "                continue # When it is not the true class the value added is 0, so we ignore it\n",
    "                        \n",
    "            loss += -((w[i] * np.log(preds[i]) / counts[i]) / (np.sum(w)))\n",
    "            \n",
    "    return loss # loss/len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_IMAGES:\n",
    "    print('[INFO] Preprocessing Images...')\n",
    "    \n",
    "    df = pd.read_csv(TABULAR_DATA_PATH)\n",
    "    \n",
    "    if N_JOBS == 1:\n",
    "        for name in tqdm(df[\"image_id\"]):\n",
    "            preprocess_image(IMAGE_PATH, IMAGE_PATH, name, MAX_IMAGE_SIZE)\n",
    "    else: \n",
    "        # It has problems with space\n",
    "        with multiprocessing.Pool(processes=os.cpu_count() if N_JOBS == -1 else N_JOBS) as pool:\n",
    "            pool.starmap(\n",
    "                func=preprocess_image, \n",
    "                iterable=[(IMAGE_PATH, IMAGE_PATH, name, MAX_IMAGE_SIZE) for name in df[\"image_id\"]]\n",
    "            )\n",
    "\n",
    "            pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predictions, y = predict_TTA(\\n    model=model,\\n    base_dataloader=base_test_dataloader,\\n    aug_dataloader=aug_test_dataloader,\\n    device=DEVICE\\n)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.9454, 0.8770, 0.8563), std=(0.1034, 0.2154, 0.2716))\n",
    "])\n",
    "\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), \n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.9454, 0.8770, 0.8563), std=(0.1034, 0.2154, 0.2716))\n",
    "])\n",
    "\n",
    "base_test_dataloader, aug_test_dataloader, classes = create_TTA_dataloader(\n",
    "    tabular_data=TABULAR_DATA_PATH,\n",
    "    img_root_dir=IMAGE_PATH,\n",
    "    base_transforms=base_transform,\n",
    "    aug_transforms=aug_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model = create_convnext_model('b')\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f=MODEL_PATH,\n",
    "        map_location=torch.device(DEVICE)  # load to CPU\n",
    "    )\n",
    ")\n",
    "\n",
    "predictions, y = predict_TTA(\n",
    "    model=model,\n",
    "    base_dataloader=base_test_dataloader,\n",
    "    aug_dataloader=aug_test_dataloader,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([base_test_dataloader.dataset.class_to_idx[label] for label in test_df['label']])\n",
    "\n",
    "auc = roc_auc_score(y.numpy(), prob['LAA'].to_numpy())\n",
    "multi_class_log_loss = multi_class_logarithmic_loss(y.numpy(), prob.to_numpy())\n",
    "\n",
    "#print(f'Accuracy = {torch.sum(y == torch.round(predictions).type(torch.int))/len(predictions)*100:.2f}')\n",
    "print(f'AUC = {auc:.3f}')\n",
    "print(f'Multi-class logarithmic loss = {multi_class_log_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([base_test_dataloader.dataset.class_to_idx[label] for label in test_df['label']])\n",
    "\n",
    "auc = roc_auc_score(y.numpy(), predictions.numpy())\n",
    "predictions_df = pd.DataFrame({\n",
    "    'CE':1-predictions.numpy(),\n",
    "    'LAA':predictions.numpy()\n",
    "})\n",
    "multi_class_log_loss = multi_class_logarithmic_loss(y.numpy(), predictions_df.to_numpy())\n",
    "\n",
    "print(f'Accuracy = {torch.sum(y == torch.round(predictions).type(torch.int))/len(predictions)*100:.2f}')\n",
    "print(f'AUC = {auc:.3f}')\n",
    "print(f'Multi-class logarithmic loss = {multi_class_log_loss:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'patient_id':test_df['patient_id'],\n",
    "    'CE':1-predictions.numpy(),\n",
    "    'LAA':predictions.numpy()\n",
    "})\n",
    "\n",
    "predictions_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "691edecb9f7cb7a0b3f20db7bfc8f0324b9aa74136e160810d1d33591264aaa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
